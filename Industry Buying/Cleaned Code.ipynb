{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "02284325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import sys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "57792d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function finds all the category which can be used for collecting the datas\n",
    "def get_the_category_urls(url_having_all_categories):\n",
    "    #validate whether the url is present or not\n",
    "    if not validators.url(url_having_all_categories):\n",
    "        return None, None, 1\n",
    "    url = url_having_all_categories\n",
    "    max_retries = 10\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status() # Raises HTTPError for bad responses\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#             print(\"Title:\", soup.title.text)\n",
    "            break\n",
    "        except requests.RequestException as e:\n",
    "#             print(f\"Attempt {attempt}: Request failed - {e}\")\n",
    "            pass\n",
    "\n",
    "    else:\n",
    "#         print(f\"Failed to retrieve the content after {max_retries} attempts.\")\n",
    "        return None, None, 1\n",
    "\n",
    "    \n",
    "    all_hrefs = [a.get('href') for a in soup.find_all('a', class_='catHead')]\n",
    "    all_hrefs=  [url[:-12]+i for i in all_hrefs]\n",
    "    \n",
    "    category_elements = soup.find_all('a', class_='catHead')\n",
    "    category_names= [element.text for element in category_elements]\n",
    "    \n",
    "    return all_hrefs,category_names, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1764671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what this function do is go inside all the category url and finds all the product's url\n",
    "#we return three thing\n",
    "#1.list_subcategories->having the urls for the product\n",
    "#2.error_logs- lets say if accessing the given_url is done, we can find all the pages and subcategories which failed to load\n",
    "#3.error-if the website fails to load, we can simply return the message 1\n",
    "def find_all_urls(given_url):\n",
    "    error_logs=[]\n",
    "    list_subcategories=[]\n",
    "    url_k=given_url\n",
    "\n",
    "    subcategory_names=[]\n",
    "\n",
    "    # url = \"https://www.hippostores.com/ihbcategory/sanitary-ware-and-bath-fittings-sbf\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    \n",
    "    #validate whether the url exist or not\n",
    "    if not validators.url(url_k):\n",
    "        return list_subcategories, subcategory_names, error_logs, 1\n",
    "    \n",
    "    #prevent from not getting a responce and getting a bad responce\n",
    "    maxtries=5\n",
    "    error=1\n",
    "    for tries in range(maxtries):\n",
    "        \n",
    "        session = requests.Session()\n",
    "        response = session.get(url_k, headers=headers)\n",
    "        if response.status_code == 200 and response.status_code != 400:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            error=0\n",
    "            break\n",
    "\n",
    "    if error==1:\n",
    "        return list_subcategories, subcategory_names, error_logs, 1\n",
    "    \n",
    "    #first we have to find the name of the category\n",
    "    \n",
    "    target_elements = soup.find_all('p', {'class': 'productTitle'})\n",
    "\n",
    "    for element in target_elements:\n",
    "        product_title = element.find('a').contents[0].strip()\n",
    "        subcategory_names.append(product_title)\n",
    "    \n",
    "\n",
    "    #list_category contains all the links for the subcategories in the specific category\n",
    "    list_category=[]\n",
    "    cat_colm_elements = soup.find_all(class_=\"cat-colm\")\n",
    "\n",
    "\n",
    "    # Extract and print the first link from each element\n",
    "    for cat_colm in cat_colm_elements:\n",
    "        href_link = \"https://www.industrybuying.com\"+cat_colm.find('a')['href']\n",
    "        list_category.append(href_link)\n",
    "\n",
    "    #so we get our list category which contains all the links for the subcategories in the specific category\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    for i in range(len(list_category)):\n",
    "        error_logs.append([])\n",
    "        #this contains all the urls of that specific subcategory\n",
    "        list_of_url_individual=[]\n",
    "\n",
    "        #link_one_category is specific url of a subcategory\n",
    "        link_one_category=list_category[i]\n",
    "        error_logs[-1].append(link_one_category)\n",
    "        headers = {\n",
    "          'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'\n",
    "        }\n",
    "        \n",
    "        \n",
    "        maxtries=5\n",
    "        error=1\n",
    "        for tries in range(maxtries):\n",
    "            session = requests.Session()\n",
    "            response = session.get(link_one_category, headers=headers)\n",
    "\n",
    "            #prevent from not getting a responce and getting a bad responce\n",
    "            if response.status_code == 200 and response.status_code != 400:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                error=0\n",
    "                error_logs[-1].append(0) #means this category is successfully captured\n",
    "                error_logs[-1].append([])\n",
    "                break\n",
    "        if error==1:\n",
    "#             error_logs[-1].append(1,[], 0, 0)\n",
    "            error_logs[-1].append(1)\n",
    "            error_logs[-1].append([])\n",
    "            error_logs[-1].append(0)\n",
    "            error_logs[-1].append(0)\n",
    "            continue\n",
    "\n",
    "        span_element = soup.find('span', class_='productslimit')\n",
    "\n",
    "        span_text = span_element.get_text()\n",
    "\n",
    "        span_text_parts = span_text.strip('()').split()\n",
    "\n",
    "        products_one_page = int(span_text_parts[0].split('-')[1])\n",
    "        total_products = int(span_text_parts[-1])\n",
    "        pages=math.ceil(total_products / products_one_page)\n",
    "\n",
    "        #now all we have to do is go page to page and pick all the url having the links\n",
    "        for page in range(pages):\n",
    "            url_page_wise=link_one_category+ f\"?page={page+1}\"\n",
    "\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'\n",
    "            }\n",
    "            \n",
    "            maxtries=5\n",
    "            error=1\n",
    "            for tries in range(maxtries):\n",
    "                session = requests.Session()\n",
    "                response = session.get(url_page_wise, headers=headers)\n",
    "                #prevent from not getting a responce and getting a bad responce\n",
    "                if response.status_code == 200 and response.status_code != 400:\n",
    "                    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                    error=0\n",
    "                    break\n",
    "                if error==1:\n",
    "                    error_logs[-1][-1].append(page)\n",
    "                    continue\n",
    "            \n",
    "                \n",
    "\n",
    "            div_elements = soup.find_all('div', class_='AH_ProductView')\n",
    "\n",
    "\n",
    "\n",
    "            # Loop through each div element\n",
    "            for div_element in div_elements:\n",
    "                # Find the first anchor element within the div\n",
    "                first_link = div_element.find('a')\n",
    "\n",
    "                # If a link is found, append its href to the list\n",
    "                if first_link:\n",
    "                    href_link = first_link.get('href')\n",
    "                    list_of_url_individual.append(href_link)\n",
    "        \n",
    "        error_logs[-1].append(len(list_of_url_individual))\n",
    "        list_subcategories.append(list_of_url_individual)\n",
    "        error_logs[-1].append(len(list(set(list_of_url_individual))))\n",
    "#         print(i, end=\" \")\n",
    "    \n",
    "    #remove duplicate from the list_subcategories\n",
    "    list_subcategories_copy=[]\n",
    "    for lis in list_subcategories:\n",
    "        lis_set=list(set(lis))\n",
    "        list_subcategories_copy.append(lis_set)\n",
    "    \n",
    "    list_subcategories=list_subcategories_copy\n",
    "    #we can return this table without any duplicate index\n",
    "    \n",
    "    \n",
    "    return list_subcategories, subcategory_names, error_logs, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dc573055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logs_table(logs, category_name, subcategory_names, category_url):\n",
    "    for log in logs:\n",
    "        log[2] = [str(num) for num in log[2]]\n",
    "        lis=log[2]\n",
    "        log[2]=', '.join(lis)\n",
    "        \n",
    "    columns=['Category URL', 'Sub Category URL', 'Category', 'Sub Category', 'Category Check', 'Sub Category Check', 'Pages Check', 'Page Not Retrieved', 'Total Product', 'Non duplicated Products']\n",
    "        \n",
    "    \n",
    "    df=pd.DataFrame(logs, columns=['Sub Category URL','Sub Category Check','Page Not Retrieved','Total Product','Non duplicated Products'])\n",
    "    df['Category URL']=category_url\n",
    "    df['Category']=category_name\n",
    "    df['Sub Category']=subcategory_names\n",
    "    df['Category Check']=0\n",
    "    df['Pages Check'] = df['Page Not Retrieved'].apply(lambda x: 0 if x == '' else 1)\n",
    "    \n",
    "    df=df[columns]\n",
    "    \n",
    "    filename=\"IndustryBuying\"+\"__\"+category_name+\"__\"+\"logs.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3ea88ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what it does is find all the prices inside the table listing the mrp and other stuff in each product\n",
    "def find_prices(soup):\n",
    "    mrp=None\n",
    "    discount=None\n",
    "    discount_flag=None\n",
    "    \n",
    "    price_text = soup.find('span', class_='mainPrice')\n",
    "    \n",
    "    \n",
    "    if price_text:\n",
    "        price_text=price_text.text\n",
    "        price_integer = int(price_text.replace('Rs.', '').replace(',', ''))\n",
    "        mrp=price_integer\n",
    "        discount_flag=0\n",
    "        discount=\"1-\"+str(mrp)\n",
    "        return mrp, discount, discount_flag, 0\n",
    "    \n",
    "    mrp_listing = soup.find('del', {'id': 'AH_ListPrice'})\n",
    "    bulk_table= soup.find('div', {'class': 'ah-bulk-qty-table'})\n",
    "    per_piece_price=soup.find('span', class_='AH_PricePerPiece')\n",
    "    \n",
    "    if mrp_listing is None and bulk_table is None and per_piece_price is None:\n",
    "        return None, None, None, 1\n",
    "\n",
    "    \n",
    "    \n",
    "    #find a condition with no discount on individual as well as on packs\n",
    "    if mrp_listing is None and bulk_table is None:\n",
    "        discount_flag=0\n",
    "        #now since there wont be any discount either ways we can have our discount as:- mrp-1\n",
    "        mrp=per_piece_price.get_text(strip=True).replace(\",\", \"\")\n",
    "        discount=\"1-\"+str(mrp)\n",
    "        \n",
    "    \n",
    "    #find a condition with discount only on 1 item \n",
    "    elif mrp_listing and bulk_table is None:\n",
    "        discount_flag=1\n",
    "        #now my discount price and my mrp would be different\n",
    "        discount=per_piece_price.get_text(strip=True).replace(\",\", \"\")\n",
    "        discount=\"1-\"+str(discount)\n",
    "        mrp=mrp_listing.get_text(strip=True).replace(\",\", \"\")\n",
    "        \n",
    "        \n",
    "    #find a condition where discount is only present on bulk\n",
    "    elif mrp_listing is None and bulk_table:\n",
    "        discount_flag=2\n",
    "        #now since there wont be any discount(individual) we can have our discount initially as:- mrp-1\n",
    "        mrp=per_piece_price.get_text(strip=True).replace(\",\", \"\")\n",
    "        discount=\"1-\"+str(mrp)\n",
    "        \n",
    "        element_texts = []\n",
    "\n",
    "        # Start the index at 0\n",
    "        index = 0\n",
    "\n",
    "        while True:\n",
    "            # Generate the class name with the current index\n",
    "            class_name = f'table-row bulk-option AH_BulkPriceOption AH_BulkPriceOption_{index}'\n",
    "\n",
    "            # Find all div elements with the specific class\n",
    "            elements = soup.find_all('div', class_=class_name)\n",
    "\n",
    "            # If elements are found, proceed\n",
    "            if elements:\n",
    "                for element in elements:\n",
    "                    # Find all div elements with class \"table-cell\" inside the current element\n",
    "                    table_cells = element.find_all('div', class_='table-cell')\n",
    "\n",
    "                    # Extract text from each \"table-cell\" and add it to the list\n",
    "                    cell_texts = [cell.get_text(strip=True) for cell in table_cells]\n",
    "                    element_texts.append(cell_texts)\n",
    "\n",
    "                # Increment the index for the next iteration\n",
    "                index += 1\n",
    "            else:\n",
    "                # If no elements are found, break the loop\n",
    "                break\n",
    "\n",
    "        # Print the list of texts for each element\n",
    "        for each_element in element_texts:\n",
    "            a=each_element[1]\n",
    "            b=each_element[2]\n",
    "            a=a.split('-')[0].strip().split('+')[0]\n",
    "            b=b.split(\" \")[-1]\n",
    "            #now we got these dudes, we can simple append this to string discount\n",
    "            discount+=\"; \"+a+\"-\"+b\n",
    "        \n",
    "    \n",
    "    #find a condition where the discount is present on both, individual and bulk\n",
    "    else:\n",
    "        discount_flag=3\n",
    "        #now we can different discount for individual and bulk\n",
    "        discount=per_piece_price.get_text(strip=True).replace(\",\", \"\")\n",
    "        discount=\"1-\"+str(discount)\n",
    "        mrp=mrp_listing.get_text(strip=True).replace(\",\", \"\") \n",
    "        \n",
    "        element_texts = []\n",
    "\n",
    "        # Start the index at 0\n",
    "        index = 0\n",
    "\n",
    "        while True:\n",
    "            # Generate the class name with the current index\n",
    "            class_name = f'table-row bulk-option AH_BulkPriceOption AH_BulkPriceOption_{index}'\n",
    "\n",
    "            # Find all div elements with the specific class\n",
    "            elements = soup.find_all('div', class_=class_name)\n",
    "\n",
    "            # If elements are found, proceed\n",
    "            if elements:\n",
    "                for element in elements:\n",
    "                    # Find all div elements with class \"table-cell\" inside the current element\n",
    "                    table_cells = element.find_all('div', class_='table-cell')\n",
    "\n",
    "                    # Extract text from each \"table-cell\" and add it to the list\n",
    "                    cell_texts = [cell.get_text(strip=True) for cell in table_cells]\n",
    "                    element_texts.append(cell_texts)\n",
    "\n",
    "                # Increment the index for the next iteration\n",
    "                index += 1\n",
    "            else:\n",
    "                # If no elements are found, break the loop\n",
    "                break\n",
    "\n",
    "        # Print the list of texts for each element\n",
    "        for each_element in element_texts:\n",
    "            a=each_element[1]\n",
    "            b=each_element[2]\n",
    "            a=a.split('-')[0].strip().split('+')[0]\n",
    "            b=b.split(\" \")[-1]\n",
    "            #now we got these dudes, we can simple append this to string discount\n",
    "            discount+=\"; \"+a+\"-\"+b\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    #our discount will be in integer but our mrp must be integer\n",
    "    mrp=int(mrp)\n",
    "    \n",
    "    \n",
    "    return mrp, discount, discount_flag, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9b4d013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is an important match\n",
      "Today is an important match\n",
      "Today is an important match\n",
      "Health Health Philips bulbs\n"
     ]
    }
   ],
   "source": [
    "#these function can be used for cleaning\n",
    "#for eg:-name of the product is:-Super Bulb with ultra shining(332743), then my name_cleaner outputs:-Super Bulb with ultra shining\n",
    "def name_cleaner(str):\n",
    "  l=str.split(' ')\n",
    "  clean_str=\"\"\n",
    "  if l[-1].isnumeric():\n",
    "    clean_str=' '.join(l[0:-2])\n",
    "  elif l[-1][1:-1].isnumeric():\n",
    "    clean_str=' '.join(l[0:-1])\n",
    "  else:\n",
    "    clean_str=str\n",
    "\n",
    "  return clean_str\n",
    "\n",
    "print(name_cleaner(\"Today is an important match - 201920\"))\n",
    "print(name_cleaner(\"Today is an important match (38929)\"))\n",
    "print(name_cleaner(\"Today is an important match\"))\n",
    "\n",
    "#string star remover and capitalizer\n",
    "def process_string(input_string):\n",
    "    cleaned_string = input_string.rstrip('.*').lower().capitalize()\n",
    "    return cleaned_string\n",
    "\n",
    "print(process_string(\"health.\"), process_string(\"health*\"), process_string(\"Philips bulbs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4498821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#once we send our both list through which we can make the dataset\n",
    "def get_dataset(list_mandatory, list_optional, set_with_columns, category_name):\n",
    "    \n",
    "    columns = [\"Primary Key\", \"Brand\", \"L1\", \"L2\", \"L3\", \"L4\", \"L5\", \"L6\", \"Product\",\n",
    "               \"Name\", \"Piece Quantity\", \"MRP\", \"Discount Price(Max)\", \"Discount Price(Min)\",\n",
    "               \"Discount Check Flag\", \"URL\"]\n",
    "\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    \n",
    "    df_mandatory = pd.DataFrame(list_mandatory, columns=columns)   \n",
    "    filename=\"IndustryBuying\"+\"__\"+category_name+\"__\"+\"MANDATORY.csv\"\n",
    "    df_mandatory.to_csv(filename,index=False)\n",
    "    #we have made the mandatory dataset\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    # Iterate through each row in list_optional\n",
    "    for row in list_optional:\n",
    "        # Create a dictionary to store values for the current row\n",
    "        row_values = {column: None for column in set_with_columns}\n",
    "\n",
    "        # Update the values for the columns present in the current row\n",
    "        for column, value in row:\n",
    "            row_values[column] = value\n",
    "\n",
    "        # Append the row to the list\n",
    "        data.append(row_values)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df_optional = pd.DataFrame(data)\n",
    "    filename=\"IndustryBuying\"+\"__\"+category_name+\"__\"+\"OPTIONAL.csv\"\n",
    "    df_optional.to_csv(filename, index=False)\n",
    "    #we have made the optional dataset\n",
    "    df=df_optional.copy()\n",
    "    # Sort columns based on the number of NaN values in each column\n",
    "    sorted_columns = df_optional.isna().sum().sort_values().index\n",
    "    df = df[sorted_columns]\n",
    "\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e39643dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collect(list_subcategories, category_name):\n",
    "    list_mandatory=[]\n",
    "    product_with_inconsistency=[]\n",
    "    set_with_columns=set()\n",
    "    list_optional=[]\n",
    "    for i in range(len(list_subcategories)):\n",
    "        for j in range(1):\n",
    "    #         url=\"https://www.industrybuying.com/knapsack-sprayer-agripro-AGR.KNA.45809501/\"\n",
    "\n",
    "            url=\"https://www.industrybuying.com\"+list_subcategories[i][j]\n",
    "\n",
    "\n",
    "            options = Options()\n",
    "            options.add_argument('--headless')\n",
    "\n",
    "            try:\n",
    "                # Attempt to open the Chrome WebDriver\n",
    "                driver = webdriver.Chrome(options=options)\n",
    "\n",
    "                # Attempt to navigate to the given URL\n",
    "                driver.get(url)\n",
    "\n",
    "            except Exception as e:\n",
    "                # Handle the exception (e.g., print an error message)\n",
    "                product_with_inconsistency.append([url, \"URL inconsistency\"])\n",
    "                # Optionally, you may want to quit the driver if an exception occurs\n",
    "                driver.quit()\n",
    "#                 print(f\"**->{len(product_with_inconsistency)}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                button = WebDriverWait(driver, 1).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"main\"]/div/div/div/div/div/div[1]/div[4]/div[2]/div[7]/div[1]/table/tbody/tr[8]/td/a')))\n",
    "                if button:\n",
    "                    button.click()\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "\n",
    "            # time.sleep(1)\n",
    "\n",
    "            try:\n",
    "                # Get the latest HTML content\n",
    "                html_content = driver.page_source\n",
    "            except Exception as e:\n",
    "                product_with_inconsistency.append([url, \"URL inconsistency\"])\n",
    "                driver.quit()\n",
    "#                 print(f\"**->{len(product_with_inconsistency)}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Use BeautifulSoup to parse the HTML content\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "            #first we have to get the mandotory fields\n",
    "            #it contains:- Primary Key, Brand, Category, Sub Category, Hidden Categories, Product, Name\n",
    "            #MRP, Discount Price, Discount Check Flag, URL\n",
    "\n",
    "\n",
    "            #lets figure out the prices and the discounts and discount flag\n",
    "            mrp, discount, discount_flag, error=find_prices(soup)\n",
    "\n",
    "            if error==1:\n",
    "                product_with_inconsistency.append([url, \"Bad Gateway inconsistency\"])\n",
    "#                 print(f\"Bad Gateway ->{len(product_with_inconsistency)}\")\n",
    "                continue\n",
    "\n",
    "            discount_max=discount.split(\";\")[0].split(\"-\")[1]\n",
    "            discount_min=discount.split(\"; \")[-1].split(\"-\")[-1]\n",
    "\n",
    "\n",
    "            #lets get the brand\n",
    "            h2_element = soup.find('h2', class_='by')\n",
    "\n",
    "            if h2_element:\n",
    "                a_tag = h2_element.find('a')\n",
    "\n",
    "                if a_tag:\n",
    "                    brand=a_tag.text.strip()\n",
    "\n",
    "\n",
    "            #now we get the category, subcategory, name and the product\n",
    "            links = soup.select('div.commonBreadCrums a')\n",
    "\n",
    "            # Extract the text inside each link and store it in a list\n",
    "            links_list = [link.text.strip() for link in links]\n",
    "\n",
    "            #if we found out the length of the links_list is less than 4, we will continue\n",
    "            if len(links_list)<3:\n",
    "                product_with_inconsistency.append([url, \"Category listing inconsistency\"])\n",
    "#                 print(f\"**->{len(product_with_inconsistency)}\")\n",
    "                continue\n",
    "\n",
    "            \n",
    "            #we have got all the subcategory using this\n",
    "            l=links_list.copy()\n",
    "            dict_cat={}\n",
    "            for z in range(6):\n",
    "                if len(l)-2>z and z!=5:\n",
    "                    dict_cat[f\"l{z+1}\"]=l[z+1]\n",
    "                else:\n",
    "                    dict_cat[f\"l{z+1}\"]=\"\"\n",
    "\n",
    "                if z==5 and len(l)-2>z:\n",
    "                    dict_cat[f\"l{z+1}\"]=\" \".join([v for v in l[z+1:-1]])       \n",
    "    \n",
    "            product=l[-1]\n",
    "\n",
    "            #now we will have some constants\n",
    "            piece_quantity=1\n",
    "\n",
    "\n",
    "            #now we have to get the name\n",
    "            name = soup.find('span', class_='productTitle').find('h1').text.strip()\n",
    "\n",
    "\n",
    "            #first of all we would be scrapping is optional stuff\n",
    "            dict_table={}\n",
    "\n",
    "            table_element = soup.find('div', {'class': 'tabDetailsContainer', 'id': 'famSpec'})\n",
    "\n",
    "\n",
    "            # Find all div elements with class 'filterRow'\n",
    "            if table_element:\n",
    "                filter_rows = table_element.find_all('div', class_='filterRow')\n",
    "            else:\n",
    "                filter_rows=None\n",
    "            # Initialize an empty list to store the tuple pairs\n",
    "            dict_table={}\n",
    "\n",
    "\n",
    "\n",
    "            # Loop through each filter row and extract feature name and value\n",
    "            if filter_rows:\n",
    "                for row in filter_rows:\n",
    "                    key = row.find('div', class_='featureNamePr').text.strip()\n",
    "                    key=process_string(key)\n",
    "                    value = row.find('div', class_='featureValuePr').text.replace(':', '').strip()\n",
    "                    #now we have got the feature_name and feature_value\n",
    "                    #we can put this in a dictionary\n",
    "                    dict_table[key]=str(value)\n",
    "\n",
    "\n",
    "            #lets consider a scenario, if the model no is not present, we wont be definitely moving forward \n",
    "            u_id=None\n",
    "            if 'Model no' in dict_table:\n",
    "                u_id=dict_table['Model no']\n",
    "            else:\n",
    "                #if model_no not present, then put the id format as:-ibyymmddhhmmssuuuuuu (u denotes microseconds)\n",
    "                current_time = datetime.now()\n",
    "                # Format the time to \"yymmddhhmmssuuuuuu\"\n",
    "                formatted_time = current_time.strftime(\"%y%m%d%H%M%S%f\")[:]  \n",
    "                u_id=\"ib\"+formatted_time\n",
    "\n",
    "            if u_id =='-':\n",
    "                #if model_no not present, then put the id format as:-ibyymmddhhmmssuuuuuu (u denotes microseconds)\n",
    "                current_time = datetime.now()\n",
    "                # Format the time to \"yymmddhhmmssuuuuuu\"\n",
    "                formatted_time = current_time.strftime(\"%y%m%d%H%M%S%f\")[:]  \n",
    "                u_id=\"ib\"+formatted_time\n",
    "                \n",
    "            dict_table['Model no']=u_id \n",
    "\n",
    "            #now we can add all the optional columns in the set\n",
    "            for k in dict_table:\n",
    "                set_with_columns.add(k)\n",
    "\n",
    "\n",
    "            key_value_pairs_as_lists = [[key, value] for key, value in dict_table.items()]\n",
    "            list_optional.append(key_value_pairs_as_lists)\n",
    "            print(i*2+j+1)\n",
    "\n",
    "    #         print(brand)\n",
    "\n",
    "    #         print(category, subcategory, product, name, sep='\\t')\n",
    "\n",
    "    #         print(u_id, discount_flag, mrp, discount_max, discount_min, sep='\\t')\n",
    "\n",
    "            #Primary Key, Brand, Category, Sub Category, Hidden Categories, Product, Name, Piece Quantity, MRP, Discount Price(Max), Discount Price(Min), Discount Check Flag, URL\n",
    "            list_mandatory.append([u_id, brand, dict_cat[\"l1\"], dict_cat[\"l2\"], dict_cat[\"l3\"], dict_cat[\"l4\"], dict_cat[\"l5\"], dict_cat[\"l6\"], product, name, piece_quantity, mrp, discount_max, discount_min, discount_flag, url])\n",
    "#             print(len(list_mandatory))\n",
    "            \n",
    "    #now since we got two things, first is the mandatory list and second is the optional list,\n",
    "    #we can get the dataset from both of them\n",
    "    get_dataset(list_mandatory, list_optional, set_with_columns, category_name)\n",
    "    #what this function does is\n",
    "    \n",
    "\n",
    "    return product_with_inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19839fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5401bc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The structure of the urls looks like:- (urls-https://www.industrybuying.com/abrasives-642/)\n",
      "1242 1195 1275 269 350 299 363 615 398 199 847 \n",
      "1\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "19\n",
      "21\n",
      "The structure of the urls looks like:- (urls-https://www.industrybuying.com/adhesives-sealants-and-tape-2595/)\n",
      "508 7197 317 2554 1084 801 78 172 178 192 298 124 44 58 180 \n",
      "1\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "19\n",
      "21\n",
      "23\n",
      "25\n",
      "27\n",
      "29\n",
      "The structure of the urls looks like:- (urls-https://www.industrybuying.com/agriculture-garden-landscaping-2384/)\n",
      "1369 830 1139 26 237 54 346 583 162 73 1361 373 65 68 76 304 67 806 3 \n",
      "1\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "19\n",
      "21\n",
      "23\n",
      "27\n",
      "29\n",
      "31\n",
      "33\n",
      "35\n",
      "37\n",
      "The structure of the urls looks like:- (urls-https://www.industrybuying.com/appliances-17567/)\n",
      "2521 139 1316 1051 476 143 \n",
      "1\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, i_th_url \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(urls):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#implement this function and get all the url\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     ith_category_name\u001b[38;5;241m=\u001b[39mcategory_names[index]\n\u001b[0;32m---> 14\u001b[0m     list_subcategories, subcategory_names, logs, error\u001b[38;5;241m=\u001b[39m\u001b[43mfind_all_urls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi_th_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe structure of the urls looks like:- (urls-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi_th_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lis \u001b[38;5;129;01min\u001b[39;00m list_subcategories:\n",
      "Cell \u001b[0;32mIn[91], line 118\u001b[0m, in \u001b[0;36mfind_all_urls\u001b[0;34m(given_url)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tries \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(maxtries):\n\u001b[1;32m    117\u001b[0m     session \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mSession()\n\u001b[0;32m--> 118\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_page_wise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m#prevent from not getting a responce and getting a bad responce\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/Env/lib/python3.9/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Env/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/Env/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/Env/lib/python3.9/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/envs/Env/lib/python3.9/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Env/lib/python3.9/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/Env/lib/python3.9/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/anaconda3/envs/Env/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/Env/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Env/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/Env/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Env/lib/python3.9/ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/Env/lib/python3.9/ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "url_having_all_categories=\"https://www.industrybuying.com/categories/\"\n",
    "\n",
    "urls,category_names, error=get_the_category_urls(url_having_all_categories)\n",
    "\n",
    "if error==1:\n",
    "    print(\"There is problem in the url having the categories\")\n",
    "    sys.exit()\n",
    "\n",
    "# urls=['https://www.industrybuying.com/agriculture-garden-landscaping-2384/', 'unknown', 'https://www.industrybuying.com/pumps-1160/', 'https://www.industrybuying.com/solar-4050/', 'please go away', 'https://www.industrybuying.com/welding-552/']\n",
    "    \n",
    "for index, i_th_url in enumerate(urls):\n",
    "    #implement this function and get all the url\n",
    "    ith_category_name=category_names[index]\n",
    "    list_subcategories, subcategory_names, logs, error=find_all_urls(i_th_url)\n",
    "    \n",
    "    print(f\"The structure of the urls looks like:- (urls-{i_th_url})\")\n",
    "    for lis in list_subcategories:\n",
    "        print(len(lis), end=\" \")\n",
    "    print()\n",
    "    \n",
    "    #we have got the logs and error\n",
    "    #if the error ==1, we can simply return the dataframe having the heading as failed \n",
    "    if error==1:\n",
    "        data_logs = {'Category URL':[i_th_url], 'Sub Category URL':[None], 'Category':[ith_category_name], 'Sub Category':[None], \n",
    "                     'Category Check':[1], 'Sub Category Check': [0], 'Pages Check':[0], 'Page Not Retrieved':[\"\"],'Total Product':[0],'Non duplicated Products':[0]}\n",
    "        df = pd.DataFrame(data_logs)\n",
    "        filename=\"IndustryBuying\"+\"__\"+ith_category_name+\"__\"+\"logs.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        #since the data_logs has no value in it, we can dont have the need to define the mandatory, optional and inconsistent urls\n",
    "        continue\n",
    "    #we must define the logs\n",
    "    #since we got the logs, we can simply find the dataframe\n",
    "    logs_table(logs, ith_category_name, subcategory_names, i_th_url)\n",
    "    \n",
    "    \n",
    "    product_with_inconsistency=data_collect(list_subcategories, ith_category_name)\n",
    "    df = pd.DataFrame(product_with_inconsistency, columns=['URL', 'ISSUE'])\n",
    "    df['Category']=ith_category_name\n",
    "    df=df[['Category', 'URL', 'ISSUE']]\n",
    "    filename=\"IndustryBuying\"+\"__\"+ith_category_name+\"__\"+\"InconsistentProducts.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "        \n",
    "    #now all we need to do is get the links which have inconsistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1e97a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The structure of the urls looks like:- (urls-nahi hai)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# url_having_all_categories=\"https://www.industrybuying.com/categories/\"\n",
    "\n",
    "# urls,category_names, error=get_the_category_urls(url_having_all_categories)\n",
    "\n",
    "# if error==1:\n",
    "#     print(\"There is problem in the url having the categories\")\n",
    "#     sys.exit()\n",
    "\n",
    "urls=['nahi hai']\n",
    "category_names=['umhmmm']\n",
    "for index, i_th_url in enumerate(urls):\n",
    "    #implement this function and get all the url\n",
    "    ith_category_name=category_names[index]\n",
    "    list_subcategories, subcategory_names, logs, error=find_all_urls(i_th_url)\n",
    "    \n",
    "    print(f\"The structure of the urls looks like:- (urls-{i_th_url})\")\n",
    "    for lis in list_subcategories:\n",
    "        print(len(lis), end=\" \")\n",
    "    print()\n",
    "    \n",
    "    #we have got the logs and error\n",
    "    #if the error ==1, we can simply return the dataframe having the heading as failed \n",
    "    if error==1:\n",
    "        data_logs = {'Category URL':[i_th_url], 'Sub Category URL':[None], 'Category':[ith_category_name], 'Sub Category':[None], \n",
    "                     'Category Check':[1], 'Sub Category Check': [0], 'Pages Check':[0], 'Page Not Retrieved':[\"\"],'Total Product':[0],'Non duplicated Products':[0]}\n",
    "        df = pd.DataFrame(data_logs)\n",
    "        filename=\"IndustryBuying\"+\"__\"+ith_category_name+\"__\"+\"logs.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        #since the data_logs has no value in it, we can dont have the need to define the mandatory, optional and inconsistent urls\n",
    "        continue\n",
    "    #we must define the logs\n",
    "    #since we got the logs, we can simply find the dataframe\n",
    "    logs_table(logs, ith_category_name, subcategory_names, i_th_url)\n",
    "    \n",
    "    \n",
    "    product_with_inconsistency=data_collect(list_subcategories, ith_category_name)\n",
    "    df = pd.DataFrame(product_with_inconsistency, columns=['URL', 'ISSUE'])\n",
    "    df['Category']=ith_category_name\n",
    "    df=df[['Category', 'URL', 'ISSUE']]\n",
    "    filename=\"IndustryBuying\"+\"__\"+ith_category_name+\"__\"+\"InconsistentProducts.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "        \n",
    "    #now all we need to do is get the links which have inconsistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d432dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from random import randint\n",
    "\n",
    "\n",
    "directory = os.getcwd()  \n",
    "\n",
    "#lets build dataset for the inconsistent products\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith(\"InconsistentProducts.csv\")]\n",
    "\n",
    "\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    combined_df = pd.concat([df, combined_df])\n",
    "combined_df_reset = combined_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "directory = os.path.join(os.getcwd(), 'overall_logs')\n",
    "file_path = os.path.join(directory, 'summarised_InconsistentProducts.csv')\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "combined_df_reset.to_csv(file_path, index=False)\n",
    "\n",
    "\n",
    "#lets do the same for logs\n",
    "# Define the directory where the CSV files are located\n",
    "directory = os.getcwd()  \n",
    "\n",
    "# Get a list of CSV files ending with \"InconsistentProducts\" in the directory\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith(\"logs.csv\")]\n",
    "\n",
    "\n",
    "combined_df = pd.DataFrame()\n",
    "# Loop through each CSV file and append its data to the combined DataFrame\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    combined_df = pd.concat([df, combined_df])\n",
    "combined_df_reset = combined_df.reset_index(drop=True)\n",
    "combined_df_reset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "directory = os.path.join(os.getcwd(), 'overall_logs')\n",
    "file_path = os.path.join(directory, 'summarised_logs.csv')\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "combined_df_reset.to_csv(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bb3ce8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>URL</th>\n",
       "      <th>ISSUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>https://www.industrybuying.com/thermal-fogging...</td>\n",
       "      <td>Bad Gateway inconsistency</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Category  \\\n",
       "0  Agriculture Garden & Landscaping   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.industrybuying.com/thermal-fogging...   \n",
       "\n",
       "                       ISSUE  \n",
       "0  Bad Gateway inconsistency  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory where the CSV files are located\n",
    "directory = os.getcwd()  # You can change this to your desired directory\n",
    "\n",
    "# Get a list of CSV files ending with \"InconsistentProducts\" in the directory\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith(\"InconsistentProducts.csv\")]\n",
    "\n",
    "\n",
    "combined_df = pd.DataFrame()\n",
    "# Loop through each CSV file and append its data to the combined DataFrame\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    combined_df = pd.concat([df, combined_df])\n",
    "combined_df_reset = combined_df.reset_index(drop=True)\n",
    "combined_df_reset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3eeec5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category URL</th>\n",
       "      <th>Sub Category URL</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub Category</th>\n",
       "      <th>Category Check</th>\n",
       "      <th>Sub Category Check</th>\n",
       "      <th>Pages Check</th>\n",
       "      <th>Page Not Retrieved</th>\n",
       "      <th>Total Product</th>\n",
       "      <th>Non duplicated Products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Waterproofing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>559</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Paints, Lacquer &amp; Varnishes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9102</td>\n",
       "      <td>7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Sealants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Tapes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3074</td>\n",
       "      <td>2554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Surface Preparation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1235</td>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Epoxy Adhesives</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>815</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Structural Adhesives</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Anaerobic Adhesives</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Tile Adhesives</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Synthetic Resin Adhesives</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Solvent Based Adhesives</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Repairing Adhesives</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Adhesive Dispensing Equipments</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Adhesive Gum</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>https://www.industrybuying.com/adhesives-seala...</td>\n",
       "      <td>Adhesives Sealants and Tape</td>\n",
       "      <td>Cyanoacrylate Adhesives</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.industrybuying.com/appliances-17567/</td>\n",
       "      <td>https://www.industrybuying.com/appliances-1756...</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Home Appliances</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2760</td>\n",
       "      <td>2521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://www.industrybuying.com/appliances-17567/</td>\n",
       "      <td>https://www.industrybuying.com/appliances-1756...</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Television</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://www.industrybuying.com/appliances-17567/</td>\n",
       "      <td>https://www.industrybuying.com/appliances-1756...</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Kitchen Appliances</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1439</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.industrybuying.com/appliances-17567/</td>\n",
       "      <td>https://www.industrybuying.com/appliances-1756...</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Kitchen Utilities</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1339</td>\n",
       "      <td>1051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://www.industrybuying.com/appliances-17567/</td>\n",
       "      <td>https://www.industrybuying.com/appliances-1756...</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Cooktops</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>https://www.industrybuying.com/appliances-17567/</td>\n",
       "      <td>https://www.industrybuying.com/appliances-1756...</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nahi hai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>umhmmm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Brush Cutter and Accessories</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1485</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Sprayers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>888</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Garden Hand Tools</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1174</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Grain Processing Machine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Harvester</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>254</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Chaff Cutter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Lawn Mower</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>346</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Chain Saws</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>604</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Agriculture Implements</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Water Pump Sets</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Fertilizer and Pest Control</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526</td>\n",
       "      <td>1361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Earth Auger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>404</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Fogging Machine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Pest and Animal Repellant</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Blowers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Weed Control Mats</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>308</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Artificial Grass</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Garden Watering tools</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>912</td>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Agriculture Garden &amp; Landscaping</td>\n",
       "      <td>Agriculture &amp; Gardening - Made In Japan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/</td>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/c...</td>\n",
       "      <td>Abrasives</td>\n",
       "      <td>Cutting Blades &amp; Disc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1463</td>\n",
       "      <td>1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/</td>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/a...</td>\n",
       "      <td>Abrasives</td>\n",
       "      <td>Abrasive Disc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1378</td>\n",
       "      <td>1195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/</td>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/a...</td>\n",
       "      <td>Abrasives</td>\n",
       "      <td>Abrasive Wheels</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/</td>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/a...</td>\n",
       "      <td>Abrasives</td>\n",
       "      <td>Abrasive Rolls</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/</td>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/a...</td>\n",
       "      <td>Abrasives</td>\n",
       "      <td>Abrasive Pads</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>361</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/</td>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/i...</td>\n",
       "      <td>Abrasives</td>\n",
       "      <td>Industrial &amp; Machine Brushes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>330</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/</td>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/a...</td>\n",
       "      <td>Abrasives</td>\n",
       "      <td>Abrasive Belts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>367</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/</td>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/a...</td>\n",
       "      <td>Abrasives</td>\n",
       "      <td>Abrasive Tools and Accessories</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>728</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/</td>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/a...</td>\n",
       "      <td>Abrasives</td>\n",
       "      <td>Abrasive Sheets</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>488</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/</td>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/s...</td>\n",
       "      <td>Abrasives</td>\n",
       "      <td>Sanding &amp; Polishing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/</td>\n",
       "      <td>https://www.industrybuying.com/abrasives-642/d...</td>\n",
       "      <td>Abrasives</td>\n",
       "      <td>Drill Bits and Chisel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1185</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Category URL  \\\n",
       "0   https://www.industrybuying.com/adhesives-seala...   \n",
       "1   https://www.industrybuying.com/adhesives-seala...   \n",
       "2   https://www.industrybuying.com/adhesives-seala...   \n",
       "3   https://www.industrybuying.com/adhesives-seala...   \n",
       "4   https://www.industrybuying.com/adhesives-seala...   \n",
       "5   https://www.industrybuying.com/adhesives-seala...   \n",
       "6   https://www.industrybuying.com/adhesives-seala...   \n",
       "7   https://www.industrybuying.com/adhesives-seala...   \n",
       "8   https://www.industrybuying.com/adhesives-seala...   \n",
       "9   https://www.industrybuying.com/adhesives-seala...   \n",
       "10  https://www.industrybuying.com/adhesives-seala...   \n",
       "11  https://www.industrybuying.com/adhesives-seala...   \n",
       "12  https://www.industrybuying.com/adhesives-seala...   \n",
       "13  https://www.industrybuying.com/adhesives-seala...   \n",
       "14  https://www.industrybuying.com/adhesives-seala...   \n",
       "15   https://www.industrybuying.com/appliances-17567/   \n",
       "16   https://www.industrybuying.com/appliances-17567/   \n",
       "17   https://www.industrybuying.com/appliances-17567/   \n",
       "18   https://www.industrybuying.com/appliances-17567/   \n",
       "19   https://www.industrybuying.com/appliances-17567/   \n",
       "20   https://www.industrybuying.com/appliances-17567/   \n",
       "21                                           nahi hai   \n",
       "22  https://www.industrybuying.com/agriculture-gar...   \n",
       "23  https://www.industrybuying.com/agriculture-gar...   \n",
       "24  https://www.industrybuying.com/agriculture-gar...   \n",
       "25  https://www.industrybuying.com/agriculture-gar...   \n",
       "26  https://www.industrybuying.com/agriculture-gar...   \n",
       "27  https://www.industrybuying.com/agriculture-gar...   \n",
       "28  https://www.industrybuying.com/agriculture-gar...   \n",
       "29  https://www.industrybuying.com/agriculture-gar...   \n",
       "30  https://www.industrybuying.com/agriculture-gar...   \n",
       "31  https://www.industrybuying.com/agriculture-gar...   \n",
       "32  https://www.industrybuying.com/agriculture-gar...   \n",
       "33  https://www.industrybuying.com/agriculture-gar...   \n",
       "34  https://www.industrybuying.com/agriculture-gar...   \n",
       "35  https://www.industrybuying.com/agriculture-gar...   \n",
       "36  https://www.industrybuying.com/agriculture-gar...   \n",
       "37  https://www.industrybuying.com/agriculture-gar...   \n",
       "38  https://www.industrybuying.com/agriculture-gar...   \n",
       "39  https://www.industrybuying.com/agriculture-gar...   \n",
       "40  https://www.industrybuying.com/agriculture-gar...   \n",
       "41      https://www.industrybuying.com/abrasives-642/   \n",
       "42      https://www.industrybuying.com/abrasives-642/   \n",
       "43      https://www.industrybuying.com/abrasives-642/   \n",
       "44      https://www.industrybuying.com/abrasives-642/   \n",
       "45      https://www.industrybuying.com/abrasives-642/   \n",
       "46      https://www.industrybuying.com/abrasives-642/   \n",
       "47      https://www.industrybuying.com/abrasives-642/   \n",
       "48      https://www.industrybuying.com/abrasives-642/   \n",
       "49      https://www.industrybuying.com/abrasives-642/   \n",
       "50      https://www.industrybuying.com/abrasives-642/   \n",
       "51      https://www.industrybuying.com/abrasives-642/   \n",
       "\n",
       "                                     Sub Category URL  \\\n",
       "0   https://www.industrybuying.com/adhesives-seala...   \n",
       "1   https://www.industrybuying.com/adhesives-seala...   \n",
       "2   https://www.industrybuying.com/adhesives-seala...   \n",
       "3   https://www.industrybuying.com/adhesives-seala...   \n",
       "4   https://www.industrybuying.com/adhesives-seala...   \n",
       "5   https://www.industrybuying.com/adhesives-seala...   \n",
       "6   https://www.industrybuying.com/adhesives-seala...   \n",
       "7   https://www.industrybuying.com/adhesives-seala...   \n",
       "8   https://www.industrybuying.com/adhesives-seala...   \n",
       "9   https://www.industrybuying.com/adhesives-seala...   \n",
       "10  https://www.industrybuying.com/adhesives-seala...   \n",
       "11  https://www.industrybuying.com/adhesives-seala...   \n",
       "12  https://www.industrybuying.com/adhesives-seala...   \n",
       "13  https://www.industrybuying.com/adhesives-seala...   \n",
       "14  https://www.industrybuying.com/adhesives-seala...   \n",
       "15  https://www.industrybuying.com/appliances-1756...   \n",
       "16  https://www.industrybuying.com/appliances-1756...   \n",
       "17  https://www.industrybuying.com/appliances-1756...   \n",
       "18  https://www.industrybuying.com/appliances-1756...   \n",
       "19  https://www.industrybuying.com/appliances-1756...   \n",
       "20  https://www.industrybuying.com/appliances-1756...   \n",
       "21                                                NaN   \n",
       "22  https://www.industrybuying.com/agriculture-gar...   \n",
       "23  https://www.industrybuying.com/agriculture-gar...   \n",
       "24  https://www.industrybuying.com/agriculture-gar...   \n",
       "25  https://www.industrybuying.com/agriculture-gar...   \n",
       "26  https://www.industrybuying.com/agriculture-gar...   \n",
       "27  https://www.industrybuying.com/agriculture-gar...   \n",
       "28  https://www.industrybuying.com/agriculture-gar...   \n",
       "29  https://www.industrybuying.com/agriculture-gar...   \n",
       "30  https://www.industrybuying.com/agriculture-gar...   \n",
       "31  https://www.industrybuying.com/agriculture-gar...   \n",
       "32  https://www.industrybuying.com/agriculture-gar...   \n",
       "33  https://www.industrybuying.com/agriculture-gar...   \n",
       "34  https://www.industrybuying.com/agriculture-gar...   \n",
       "35  https://www.industrybuying.com/agriculture-gar...   \n",
       "36  https://www.industrybuying.com/agriculture-gar...   \n",
       "37  https://www.industrybuying.com/agriculture-gar...   \n",
       "38  https://www.industrybuying.com/agriculture-gar...   \n",
       "39  https://www.industrybuying.com/agriculture-gar...   \n",
       "40  https://www.industrybuying.com/agriculture-gar...   \n",
       "41  https://www.industrybuying.com/abrasives-642/c...   \n",
       "42  https://www.industrybuying.com/abrasives-642/a...   \n",
       "43  https://www.industrybuying.com/abrasives-642/a...   \n",
       "44  https://www.industrybuying.com/abrasives-642/a...   \n",
       "45  https://www.industrybuying.com/abrasives-642/a...   \n",
       "46  https://www.industrybuying.com/abrasives-642/i...   \n",
       "47  https://www.industrybuying.com/abrasives-642/a...   \n",
       "48  https://www.industrybuying.com/abrasives-642/a...   \n",
       "49  https://www.industrybuying.com/abrasives-642/a...   \n",
       "50  https://www.industrybuying.com/abrasives-642/s...   \n",
       "51  https://www.industrybuying.com/abrasives-642/d...   \n",
       "\n",
       "                            Category                             Sub Category  \\\n",
       "0        Adhesives Sealants and Tape                            Waterproofing   \n",
       "1        Adhesives Sealants and Tape              Paints, Lacquer & Varnishes   \n",
       "2        Adhesives Sealants and Tape                                 Sealants   \n",
       "3        Adhesives Sealants and Tape                                    Tapes   \n",
       "4        Adhesives Sealants and Tape                      Surface Preparation   \n",
       "5        Adhesives Sealants and Tape                          Epoxy Adhesives   \n",
       "6        Adhesives Sealants and Tape                     Structural Adhesives   \n",
       "7        Adhesives Sealants and Tape                      Anaerobic Adhesives   \n",
       "8        Adhesives Sealants and Tape                           Tile Adhesives   \n",
       "9        Adhesives Sealants and Tape                Synthetic Resin Adhesives   \n",
       "10       Adhesives Sealants and Tape                  Solvent Based Adhesives   \n",
       "11       Adhesives Sealants and Tape                      Repairing Adhesives   \n",
       "12       Adhesives Sealants and Tape           Adhesive Dispensing Equipments   \n",
       "13       Adhesives Sealants and Tape                             Adhesive Gum   \n",
       "14       Adhesives Sealants and Tape                  Cyanoacrylate Adhesives   \n",
       "15                        Appliances                          Home Appliances   \n",
       "16                        Appliances                               Television   \n",
       "17                        Appliances                       Kitchen Appliances   \n",
       "18                        Appliances                        Kitchen Utilities   \n",
       "19                        Appliances                                 Cooktops   \n",
       "20                        Appliances                            Personal Care   \n",
       "21                            umhmmm                                      NaN   \n",
       "22  Agriculture Garden & Landscaping             Brush Cutter and Accessories   \n",
       "23  Agriculture Garden & Landscaping                                 Sprayers   \n",
       "24  Agriculture Garden & Landscaping                        Garden Hand Tools   \n",
       "25  Agriculture Garden & Landscaping                 Grain Processing Machine   \n",
       "26  Agriculture Garden & Landscaping                                Harvester   \n",
       "27  Agriculture Garden & Landscaping                             Chaff Cutter   \n",
       "28  Agriculture Garden & Landscaping                               Lawn Mower   \n",
       "29  Agriculture Garden & Landscaping                               Chain Saws   \n",
       "30  Agriculture Garden & Landscaping                   Agriculture Implements   \n",
       "31  Agriculture Garden & Landscaping                          Water Pump Sets   \n",
       "32  Agriculture Garden & Landscaping              Fertilizer and Pest Control   \n",
       "33  Agriculture Garden & Landscaping                              Earth Auger   \n",
       "34  Agriculture Garden & Landscaping                          Fogging Machine   \n",
       "35  Agriculture Garden & Landscaping                Pest and Animal Repellant   \n",
       "36  Agriculture Garden & Landscaping                                  Blowers   \n",
       "37  Agriculture Garden & Landscaping                        Weed Control Mats   \n",
       "38  Agriculture Garden & Landscaping                         Artificial Grass   \n",
       "39  Agriculture Garden & Landscaping                    Garden Watering tools   \n",
       "40  Agriculture Garden & Landscaping  Agriculture & Gardening - Made In Japan   \n",
       "41                         Abrasives                    Cutting Blades & Disc   \n",
       "42                         Abrasives                            Abrasive Disc   \n",
       "43                         Abrasives                          Abrasive Wheels   \n",
       "44                         Abrasives                           Abrasive Rolls   \n",
       "45                         Abrasives                            Abrasive Pads   \n",
       "46                         Abrasives             Industrial & Machine Brushes   \n",
       "47                         Abrasives                           Abrasive Belts   \n",
       "48                         Abrasives           Abrasive Tools and Accessories   \n",
       "49                         Abrasives                          Abrasive Sheets   \n",
       "50                         Abrasives                      Sanding & Polishing   \n",
       "51                         Abrasives                    Drill Bits and Chisel   \n",
       "\n",
       "    Category Check  Sub Category Check  Pages Check  Page Not Retrieved  \\\n",
       "0                0                   0            0                 NaN   \n",
       "1                0                   0            0                 NaN   \n",
       "2                0                   0            0                 NaN   \n",
       "3                0                   0            0                 NaN   \n",
       "4                0                   0            0                 NaN   \n",
       "5                0                   0            0                 NaN   \n",
       "6                0                   0            0                 NaN   \n",
       "7                0                   0            0                 NaN   \n",
       "8                0                   0            0                 NaN   \n",
       "9                0                   0            0                 NaN   \n",
       "10               0                   0            0                 NaN   \n",
       "11               0                   0            0                 NaN   \n",
       "12               0                   0            0                 NaN   \n",
       "13               0                   0            0                 NaN   \n",
       "14               0                   0            0                 NaN   \n",
       "15               0                   0            1                27.0   \n",
       "16               0                   0            0                 NaN   \n",
       "17               0                   0            0                 NaN   \n",
       "18               0                   0            0                 NaN   \n",
       "19               0                   0            1                 7.0   \n",
       "20               0                   0            1                 0.0   \n",
       "21               1                   0            0                 NaN   \n",
       "22               0                   0            0                 NaN   \n",
       "23               0                   0            0                 NaN   \n",
       "24               0                   0            0                 NaN   \n",
       "25               0                   0            0                 NaN   \n",
       "26               0                   0            0                 NaN   \n",
       "27               0                   0            0                 NaN   \n",
       "28               0                   0            0                 NaN   \n",
       "29               0                   0            0                 NaN   \n",
       "30               0                   0            0                 NaN   \n",
       "31               0                   0            0                 NaN   \n",
       "32               0                   0            0                 NaN   \n",
       "33               0                   0            0                 NaN   \n",
       "34               0                   0            0                 NaN   \n",
       "35               0                   0            0                 NaN   \n",
       "36               0                   0            0                 NaN   \n",
       "37               0                   0            0                 NaN   \n",
       "38               0                   0            0                 NaN   \n",
       "39               0                   0            1                 3.0   \n",
       "40               0                   0            0                 NaN   \n",
       "41               0                   0            0                 NaN   \n",
       "42               0                   0            0                 NaN   \n",
       "43               0                   0            0                 NaN   \n",
       "44               0                   0            0                 NaN   \n",
       "45               0                   0            0                 NaN   \n",
       "46               0                   0            0                 NaN   \n",
       "47               0                   0            0                 NaN   \n",
       "48               0                   0            0                 NaN   \n",
       "49               0                   0            0                 NaN   \n",
       "50               0                   0            0                 NaN   \n",
       "51               0                   0            0                 NaN   \n",
       "\n",
       "    Total Product  Non duplicated Products  \n",
       "0             559                      508  \n",
       "1            9102                     7197  \n",
       "2             322                      317  \n",
       "3            3074                     2554  \n",
       "4            1235                     1084  \n",
       "5             815                      801  \n",
       "6              79                       78  \n",
       "7             172                      172  \n",
       "8             180                      178  \n",
       "9             193                      192  \n",
       "10            336                      298  \n",
       "11            137                      124  \n",
       "12             44                       44  \n",
       "13             58                       58  \n",
       "14            185                      180  \n",
       "15           2760                     2521  \n",
       "16            150                      139  \n",
       "17           1439                     1316  \n",
       "18           1339                     1051  \n",
       "19            476                      476  \n",
       "20            143                      143  \n",
       "21              0                        0  \n",
       "22           1485                     1369  \n",
       "23            888                      830  \n",
       "24           1174                     1139  \n",
       "25             26                       26  \n",
       "26            254                      237  \n",
       "27             54                       54  \n",
       "28            346                      346  \n",
       "29            604                      583  \n",
       "30            162                      162  \n",
       "31             73                       73  \n",
       "32           1526                     1361  \n",
       "33            404                      373  \n",
       "34             65                       65  \n",
       "35             72                       68  \n",
       "36             76                       76  \n",
       "37            308                      304  \n",
       "38             67                       67  \n",
       "39            912                      806  \n",
       "40              3                        3  \n",
       "41           1463                     1242  \n",
       "42           1378                     1195  \n",
       "43           1352                     1275  \n",
       "44            277                      269  \n",
       "45            361                      350  \n",
       "46            330                      299  \n",
       "47            367                      363  \n",
       "48            728                      615  \n",
       "49            488                      398  \n",
       "50            199                      199  \n",
       "51           1185                      847  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory where the CSV files are located\n",
    "directory = os.getcwd()  # You can change this to your desired directory\n",
    "\n",
    "# Get a list of CSV files ending with \"InconsistentProducts\" in the directory\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith(\"logs.csv\")]\n",
    "\n",
    "\n",
    "combined_df = pd.DataFrame()\n",
    "# Loop through each CSV file and append its data to the combined DataFrame\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    combined_df = pd.concat([df, combined_df])\n",
    "combined_df_reset = combined_df.reset_index(drop=True)\n",
    "combined_df_reset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd22f96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6128d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb68c22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54decf02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65fcf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_th_url=\"https://www.industrybuying.com/agriculture-garden-landscaping-2384/\"\n",
    "ist_subcategories, subcategory_names, logs, error=find_all_urls(i_th_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aad111cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category URL</th>\n",
       "      <th>Sub Category URL</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub Category</th>\n",
       "      <th>Category Check</th>\n",
       "      <th>Sub Category Check</th>\n",
       "      <th>Pages Check</th>\n",
       "      <th>Page Not Retrieved</th>\n",
       "      <th>Total Product</th>\n",
       "      <th>Non duplicated Products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Brush Cutter and Accessories</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1484</td>\n",
       "      <td>1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Sprayers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>885</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Garden Hand Tools</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1173</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Grain Processing Machine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Harvester</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>253</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Chaff Cutter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Lawn Mower</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>346</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Chain Saws</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>604</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Agriculture Implements</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>162</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Water Pump Sets</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Fertilizer and Pest Control</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1526</td>\n",
       "      <td>1268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Earth Auger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>404</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Fogging Machine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Pest and Animal Repellant</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Blowers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Weed Control Mats</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>308</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Artificial Grass</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Garden Watering tools</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>909</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>https://www.industrybuying.com/agriculture-gar...</td>\n",
       "      <td>Kuch nahi</td>\n",
       "      <td>Agriculture &amp; Gardening - Made In Japan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Category URL  \\\n",
       "0   https://www.industrybuying.com/agriculture-gar...   \n",
       "1   https://www.industrybuying.com/agriculture-gar...   \n",
       "2   https://www.industrybuying.com/agriculture-gar...   \n",
       "3   https://www.industrybuying.com/agriculture-gar...   \n",
       "4   https://www.industrybuying.com/agriculture-gar...   \n",
       "5   https://www.industrybuying.com/agriculture-gar...   \n",
       "6   https://www.industrybuying.com/agriculture-gar...   \n",
       "7   https://www.industrybuying.com/agriculture-gar...   \n",
       "8   https://www.industrybuying.com/agriculture-gar...   \n",
       "9   https://www.industrybuying.com/agriculture-gar...   \n",
       "10  https://www.industrybuying.com/agriculture-gar...   \n",
       "11  https://www.industrybuying.com/agriculture-gar...   \n",
       "12  https://www.industrybuying.com/agriculture-gar...   \n",
       "13  https://www.industrybuying.com/agriculture-gar...   \n",
       "14  https://www.industrybuying.com/agriculture-gar...   \n",
       "15  https://www.industrybuying.com/agriculture-gar...   \n",
       "16  https://www.industrybuying.com/agriculture-gar...   \n",
       "17  https://www.industrybuying.com/agriculture-gar...   \n",
       "18  https://www.industrybuying.com/agriculture-gar...   \n",
       "\n",
       "                                     Sub Category URL   Category  \\\n",
       "0   https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "1   https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "2   https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "3   https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "4   https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "5   https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "6   https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "7   https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "8   https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "9   https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "10  https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "11  https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "12  https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "13  https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "14  https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "15  https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "16  https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "17  https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "18  https://www.industrybuying.com/agriculture-gar...  Kuch nahi   \n",
       "\n",
       "                               Sub Category  Category Check  \\\n",
       "0              Brush Cutter and Accessories               0   \n",
       "1                                  Sprayers               0   \n",
       "2                         Garden Hand Tools               0   \n",
       "3                  Grain Processing Machine               0   \n",
       "4                                 Harvester               0   \n",
       "5                              Chaff Cutter               0   \n",
       "6                                Lawn Mower               0   \n",
       "7                                Chain Saws               0   \n",
       "8                    Agriculture Implements               0   \n",
       "9                           Water Pump Sets               0   \n",
       "10              Fertilizer and Pest Control               0   \n",
       "11                              Earth Auger               0   \n",
       "12                          Fogging Machine               0   \n",
       "13                Pest and Animal Repellant               0   \n",
       "14                                  Blowers               0   \n",
       "15                        Weed Control Mats               0   \n",
       "16                         Artificial Grass               0   \n",
       "17                    Garden Watering tools               0   \n",
       "18  Agriculture & Gardening - Made In Japan               0   \n",
       "\n",
       "    Sub Category Check  Pages Check Page Not Retrieved  Total Product  \\\n",
       "0                    0            0                              1484   \n",
       "1                    0            0                               885   \n",
       "2                    0            0                              1173   \n",
       "3                    0            0                                26   \n",
       "4                    0            0                               253   \n",
       "5                    0            0                                54   \n",
       "6                    0            0                               346   \n",
       "7                    0            0                               604   \n",
       "8                    0            0                               162   \n",
       "9                    0            0                                66   \n",
       "10                   0            0                              1526   \n",
       "11                   0            0                               404   \n",
       "12                   0            0                                62   \n",
       "13                   0            0                                72   \n",
       "14                   0            0                                76   \n",
       "15                   0            0                               308   \n",
       "16                   0            0                                67   \n",
       "17                   0            0                               909   \n",
       "18                   0            0                                 3   \n",
       "\n",
       "    Non duplicated Products  \n",
       "0                      1307  \n",
       "1                       798  \n",
       "2                      1043  \n",
       "3                        26  \n",
       "4                       233  \n",
       "5                        54  \n",
       "6                       332  \n",
       "7                       557  \n",
       "8                       153  \n",
       "9                        66  \n",
       "10                     1268  \n",
       "11                      381  \n",
       "12                       62  \n",
       "13                       72  \n",
       "14                       76  \n",
       "15                      245  \n",
       "16                       67  \n",
       "17                      808  \n",
       "18                        3  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b=logs_table(logs, ith_category_name, subcategory_names, i_th_url)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "767187a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.industrybuying.com/agriculture-garden-landscaping-2384/'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_th_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d0e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59e7a38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1285 755 1068 29 238 54 361 565 153 65 1388 388 60 85 77 291 160 795 3 \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list_subcategories)):\n",
    "    print(len(list_subcategories[i]), end=\" \")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8c4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0eab4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28c2a9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IndustryBuying__Agriculture,Garden&Landscaping__MANDATORY.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_string=\"IndustryBuying\"+\"__\"+\"Agriculture, Garden & Landscaping\"+\"__\"+\"MANDATORY.csv\"\n",
    "original_string.strip().replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07c58fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
